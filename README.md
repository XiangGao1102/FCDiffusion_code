# Frequency-Controlled-Diffusion-Model

# Introduction
This project tackles the problem of text-guided image-to-image translation (I2I), i.e., translating a source image with a natural-language text prompt. We harness the immense generative power of the pre-trained large-scale text-to-image diffusion model and extend it from text-to-image generation to text-guided I2I, providing intelligent tools for image manipulation or editing tasks. <br>

Observing that I2I has diverse application scenarios emphasizing different I2I correlations (e.g., style, structure, layout, contour, etc.) between the source and translated images, it is difficult for a single existing method to suit all I2I correlations well. This inspires us to design a unified framework allowing flexible control of diverse I2I correlations and thus applies to diverse I2I application scenarios. 
